{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamurasi-Jordan-Arthur/Year-II-AI/blob/main/21U08812EVE_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7daa176",
      "metadata": {
        "id": "e7daa176"
      },
      "source": [
        "# 21/U/08812/EVE    AND     21/U/12682\n",
        "#### Kamurasi jordan arthur                 //             Alabyeekobo Suubi Brain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f776dba",
      "metadata": {
        "id": "8f776dba"
      },
      "source": [
        "## Objective \n",
        "- Objective is to try a predict the co2emmisions given feature composition\n",
        "- Also used additional clustering algorithm to find the the hidden relation ship between the highwaympg and year over the years\n",
        "### Below are the description of the data set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "628787ce",
      "metadata": {
        "id": "628787ce"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "053f7f97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "053f7f97",
        "outputId": "62c449e0-7fd8-4c38-e061-02f1b90df55f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-78317dce5099>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mveichles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/vehicles.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# bikes = pd.read_csv(\"bikes.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/vehicles.csv'"
          ]
        }
      ],
      "source": [
        "veichles = pd.read_csv(\"/content/vehicles.csv\")\n",
        "# bikes = pd.read_csv(\"bikes.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e37d858",
      "metadata": {
        "id": "1e37d858"
      },
      "source": [
        "## A veiw of my chossen data set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QQXtrUSWrXuK"
      },
      "id": "QQXtrUSWrXuK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0b424e",
      "metadata": {
        "id": "9f0b424e"
      },
      "outputs": [],
      "source": [
        "veichles.head(5)\n",
        "# bikes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c86715",
      "metadata": {
        "id": "79c86715"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bad39d",
      "metadata": {
        "id": "47bad39d"
      },
      "outputs": [],
      "source": [
        "veichles.info()\n",
        "veichles.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aed6e565",
      "metadata": {
        "id": "aed6e565"
      },
      "outputs": [],
      "source": [
        "veichles.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ce4e3b",
      "metadata": {
        "id": "21ce4e3b"
      },
      "outputs": [],
      "source": [
        "for x in veichles.columns:\n",
        "    if veichles[x].dtype == 'object':\n",
        "        print(veichles[x].describe())\n",
        "        print('\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73efd4e7",
      "metadata": {
        "id": "73efd4e7"
      },
      "source": [
        "## Data set Visualisation\n",
        "### mean C02 emissions as per number of cylinders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16188ce0",
      "metadata": {
        "id": "16188ce0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "minmax = MinMaxScaler()\n",
        "x = veichles.groupby('cylinders')['co2emissions'].mean().reset_index()\n",
        "\n",
        "# x['co2emissions']=minmax.fit_transform(x['co2emissions'].to_frame())\n",
        "x.plot(kind = 'bar', x = 'cylinders', y = 'co2emissions', color = 'black')\n",
        "x.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ddb397",
      "metadata": {
        "id": "d1ddb397"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dad0d2ba",
      "metadata": {
        "id": "dad0d2ba"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "le = LabelEncoder()\n",
        "x = veichles.pivot(columns = 'drive', values = 'co2emissions')\n",
        "x.plot(kind = 'box', figsize = (10,6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c5324be",
      "metadata": {
        "id": "6c5324be"
      },
      "outputs": [],
      "source": [
        "plt.scatter(veichles['citympg'],veichles['highwaympg'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad55f48",
      "metadata": {
        "id": "fad55f48"
      },
      "outputs": [],
      "source": [
        "veichles.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0ad969",
      "metadata": {
        "id": "bf0ad969"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder,StandardScaler\n",
        "le = LabelEncoder()\n",
        "\n",
        "# droping columns that dont contribute tthat much to the model according to the above correlation\n",
        "# veichles.drop({'make','model','transmissionspeeds','year'}, axis = 1, inplace = True)\n",
        "\n",
        "veichles.loc[:,('year','cylinders','transmissionspeeds','drive','class','transmissiontype')] = (veichles.loc[:,('year','cylinders','transmissionspeeds','drive','class','transmissiontype')].astype('category'))\n",
        "# veichles.drop(['year','cylinders'], axis = 1)\n",
        "\n",
        "cat_columns = veichles.loc[:,('year','cylinders','transmissionspeeds','drive','class','transmissiontype')].columns\n",
        "for x in cat_columns:\n",
        "    veichles[x] = le.fit_transform(veichles[x])\n",
        "\n",
        "stdScl = StandardScaler()\n",
        "veichles.loc[:,(x for x in veichles.columns if veichles[x].dtype != 'object')] = stdScl.fit_transform(veichles.loc[:,(x for x in veichles.columns if veichles[x].dtype != 'object')])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc65c98",
      "metadata": {
        "id": "5dc65c98"
      },
      "source": [
        "### Veiw of the correlation to find best feature to use when filling the NA vaues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28fc520",
      "metadata": {
        "id": "a28fc520"
      },
      "outputs": [],
      "source": [
        "veichles.corr()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43733dbb",
      "metadata": {
        "id": "43733dbb"
      },
      "source": [
        "### Dealing with null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4656f151",
      "metadata": {
        "id": "4656f151"
      },
      "outputs": [],
      "source": [
        "mask = veichles['citympg'].isnull() & veichles['highwaympg'].isnull()\n",
        "mask0 = veichles['citympg'].isnull() & veichles['highwaympg'].isnull()\n",
        "\n",
        "print('Rows with \\'NA\\' in both \\n citympy and highwaympg are:- {}. \\n cylinders and displacement are:- {}'.format(mask.sum(), mask0.sum()))\n",
        "\n",
        "# function to derive values for NA values in the data from features with high correlation\n",
        "def fillna_value(y):\n",
        "    x,y = None,None\n",
        "    \n",
        "    \n",
        "    if y == 'citympg':        \n",
        "        x = veichles['highwaympg'].dropna().to_numpy()\n",
        "        y = veichles['citympg'].dropna().to_numpy()\n",
        "        x.resize(y.shape)\n",
        "        y.resize(y.shape)\n",
        "                \n",
        "    elif y == 'highwaympg':      \n",
        "        x = veichles['citympg'].dropna().to_numpy()\n",
        "        y = veichles['highwaympg'].dropna().to_numpy()\n",
        "        x.resize(x.shape)\n",
        "        y.resize(x.shape)\n",
        "    else:        \n",
        "        x = veichles['cylinders'].dropna().to_numpy()\n",
        "        y = veichles['displacement'].dropna().to_numpy()\n",
        "        x.resize(y.shape)\n",
        "        y.resize(y.shape)\n",
        "    a,b ,c ,d ,e = stats.linregress(x, y)   \n",
        "    return lambda x : x*a + b\n",
        "\n",
        "\n",
        "veichles.fillna({'citympg': fillna_value('citympg')(veichles['highwaympg']),\n",
        "                 'highwaympg': fillna_value('highwaympg')(veichles['citympg']),\n",
        "                 'displacement': fillna_value('displacement')(veichles['cylinders']),\n",
        "                }, inplace = True)\n",
        "\n",
        "veichles.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da333b24",
      "metadata": {
        "id": "da333b24"
      },
      "source": [
        "### Performing feature reduction with feature the model wont rely on that much"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44744cb6",
      "metadata": {
        "id": "44744cb6"
      },
      "outputs": [],
      "source": [
        "veichles.drop(['model','make','class'], axis = 1 ,inplace = True)\n",
        "le2 = LabelEncoder()\n",
        "veichles['co2_range'] = le2.fit_transform(pd.cut(veichles['co2emissions'], bins = [-6.498927e-01,6.697254e-01,6.732510e+0]))\n",
        "# sns.pairplot(veichles, hue = 'co2_range')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd99f20",
      "metadata": {
        "id": "1dd99f20"
      },
      "outputs": [],
      "source": [
        "veichles.groupby('co2_range')['co2emissions'].mean().plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35675b0c",
      "metadata": {
        "id": "35675b0c"
      },
      "source": [
        "# Working On Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a89fa1",
      "metadata": {
        "id": "86a89fa1"
      },
      "source": [
        "### Spliting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71645151",
      "metadata": {
        "id": "71645151"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = veichles.iloc[:,:8]\n",
        "Y = veichles.iloc[:,8:]\n",
        "\n",
        "x_train,x_test,y_train, y_test = train_test_split(X,Y, random_state = 29, test_size = .25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76add795",
      "metadata": {
        "id": "76add795"
      },
      "source": [
        "## logistic Regressor "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b35d9c4",
      "metadata": {
        "id": "2b35d9c4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error, mean_absolute_error\n",
        "LoR = LogisticRegression(random_state = 1)\n",
        "LoR.fit(x_train,y_train['co2_range'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f214a082",
      "metadata": {
        "id": "f214a082"
      },
      "outputs": [],
      "source": [
        "y_pred = LoR.predict(x_test)\n",
        "print('Model accuracy_score : ', accuracy_score(y_test['co2_range'],y_pred)*100)\n",
        "print('Model mean_squared_error : ', mean_squared_error(y_test['co2_range'],y_pred)*100)\n",
        "print('Model mean_absolute_error: ', mean_absolute_error(y_test['co2_range'],y_pred)*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a326fde7",
      "metadata": {
        "id": "a326fde7"
      },
      "outputs": [],
      "source": [
        "classification_report(y_test['co2_range'],y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192f5d11",
      "metadata": {
        "id": "192f5d11"
      },
      "source": [
        "## Linear Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d317b0b6",
      "metadata": {
        "id": "d317b0b6"
      },
      "outputs": [],
      "source": [
        "LiR = LinearRegression()\n",
        "LiR.fit(x_train.drop(['transmissiontype','year'], axis = 1),y_train['co2emissions'])\n",
        "# rom sklearn.linear_model import LinearRegression\n",
        "# reg = LinearRegression()\n",
        "# parameters = {\"alpha\": [1, 10, 100, 290, 500], \"fit_intercept\": [True, False], \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], }\n",
        "# grid = GridSearchCV(estimator=reg, param_grid = parameters, cv = 2, n_jobs=-1)\n",
        "# grid.fit(x_train, y_train)\n",
        "# reg.score(x_test ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53d5479",
      "metadata": {
        "id": "e53d5479"
      },
      "outputs": [],
      "source": [
        "y_pred = LiR.predict(x_test.drop(['transmissiontype','year'], axis = 1))\n",
        "\n",
        "print('model Mean_absolute_error : ', mean_absolute_error(y_test['co2emissions'] , y_pred))\n",
        "print('model Mean_squared_error : ', mean_squared_error(y_test['co2emissions'] , y_pred))\n",
        "print('model R2_score : ', LiR.score(x_test.drop(['transmissiontype','year'], axis = 1), y_test['co2emissions'].to_numpy()))\n",
        "\n",
        "# plt.scatter(y_test['co2emissions'],y_pred)\n",
        "# plt.title('Y-predict Vs y-actual')\n",
        "# plt.xlabel('co2emissions')\n",
        "# plt.ylabel('predicted emmisions')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a802d3fe",
      "metadata": {
        "id": "a802d3fe"
      },
      "source": [
        "# N.B\n",
        "### linear  and logistic models are provded as aready well turned models \n",
        "##### Furter turning of features only reduces model  performence "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597dbdf7",
      "metadata": {
        "id": "597dbdf7"
      },
      "source": [
        "## Decision Tree Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93a69507",
      "metadata": {
        "id": "93a69507"
      },
      "source": [
        "#### Turning the Criterion Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4e02ae",
      "metadata": {
        "id": "9f4e02ae"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "criterion = ['gini', 'entropy', 'log_loss']\n",
        "criterion1 = []\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "for x in criterion:\n",
        "    clf = DecisionTreeClassifier( criterion = x )\n",
        "    clf.fit(x_train, y_train['co2_range'])\n",
        "    y_pred = clf.predict(x_test)\n",
        "    criterion1.append(accuracy_score(y_pred,y_test['co2_range']))\n",
        "criterion1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6633feb3",
      "metadata": {
        "id": "6633feb3"
      },
      "source": [
        "### Fine Turning the Max_Depth paramerter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864b2073",
      "metadata": {
        "id": "864b2073"
      },
      "outputs": [],
      "source": [
        "clr = DecisionTreeRegressor()\n",
        "score = []\n",
        "depths = pd.DataFrame(range(7,52),columns = ['Max_depth'])\n",
        "\n",
        "for x in depths.values:\n",
        "    clr = DecisionTreeRegressor(max_depth = int(x))\n",
        "    clr.fit(x_train, y_train['co2emissions'])\n",
        "    y_pred = clf.predict(x_test)\n",
        "    score.append(clr.score(x_test, y_test['co2emissions']))\n",
        "    \n",
        "depths['Model_score'] = np.asarray(score).reshape(-1,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ac2257",
      "metadata": {
        "id": "58ac2257"
      },
      "outputs": [],
      "source": [
        "depths.plot(kind = 'line' ,x = 'Max_depth', y = 'Model_score',title = \"Line graph showing model perfomences with depth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d299f920",
      "metadata": {
        "id": "d299f920"
      },
      "source": [
        "## Random forest regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b29cc8c2",
      "metadata": {
        "id": "b29cc8c2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# rfr = RandomForestRegressor(criterion  ='entropy', max_leaf )\n",
        "rfr = RandomForestRegressor()\n",
        "rfr.fit(x_train,y_train['co2emissions'])\n",
        "rfr.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a586cdc",
      "metadata": {
        "id": "5a586cdc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "y_pred = rfr.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8e8ef73",
      "metadata": {
        "id": "d8e8ef73"
      },
      "source": [
        "### Random Forest model metrix using defualt parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a5a56e",
      "metadata": {
        "id": "94a5a56e"
      },
      "outputs": [],
      "source": [
        "print('Data_stdeviation and Mean;', y_test['co2emissions'].std(), y_test['co2emissions'].mean() )\n",
        "print('Predict_stdeviation and Mean ',y_pred.std() , y_pred.mean())\n",
        "print('model\\'s R2_score: ', r2_score(y_test['co2emissions'],y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e3b54f4",
      "metadata": {
        "id": "9e3b54f4"
      },
      "source": [
        "### Using GridSearchCV Search basing on to  fine tune parameters\n",
        "                                                                                            21/U/08812/EVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c947f1c7",
      "metadata": {
        "id": "c947f1c7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [80, 170, 300],\n",
        "    'max_depth': [2, 3 , 7],\n",
        "    'min_samples_split': [3, 4, 7],\n",
        "    'min_samples_leaf': [2, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "gs_cv = GridSearchCV(estimator=rfr, param_grid=param_grid,\n",
        "                     cv=3, n_jobs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d97e914",
      "metadata": {
        "id": "4d97e914"
      },
      "outputs": [],
      "source": [
        "gs_cv.fit(x_train, y_train['co2emissions'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9d9c05",
      "metadata": {
        "id": "3b9d9c05"
      },
      "outputs": [],
      "source": [
        "print('best_params:',gs_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c009daff",
      "metadata": {
        "id": "c009daff"
      },
      "outputs": [],
      "source": [
        "rfr.set_params(**gs_cv.best_params_)\n",
        "rfr.fit(x_train,y_train['co2emissions'])\n",
        "new_y_pred = rfr.predict(x_test)\n",
        "\n",
        "print('Previous_std_value and Mean;', y_pred.std() , y_pred.mean() )\n",
        "print('New_std_value and Mean ',new_y_pred.std() , new_y_pred.mean())\n",
        "print('New_model\\'s R2_score: ', r2_score(y_test['co2emissions'],new_y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96204b8f",
      "metadata": {
        "id": "96204b8f"
      },
      "source": [
        "## K-means clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61aefb87",
      "metadata": {
        "id": "61aefb87"
      },
      "source": [
        "## Parameter hyper turning\n",
        "                                                                                            21/U/08812/EVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a70b5c8a",
      "metadata": {
        "scrolled": false,
        "id": "a70b5c8a"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans()\n",
        "param_grid = {\n",
        "    'n_clusters': [2, 3, 4, 5],\n",
        "    'init': ['k-means++', 'random'],\n",
        "    'n_init': [10, 20, 30],\n",
        "    'max_iter': [130, 300,420]\n",
        "         }\n",
        "gs_cv0 = GridSearchCV(estimator=kmeans, param_grid=param_grid,\n",
        "                     cv=3, n_jobs=4)\n",
        "X = x_train.loc[:, ['year','highwaympg']]\n",
        "gs_cv0.fit(X)\n",
        "best_params = gs_cv.best_params_\n",
        "print('the best parameters:', best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ef502b",
      "metadata": {
        "id": "13ef502b"
      },
      "outputs": [],
      "source": [
        "kmeans.set_params(**gs_cv0.best_params_)\n",
        "kmeans.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad25011",
      "metadata": {
        "id": "4ad25011"
      },
      "outputs": [],
      "source": [
        "X['pred'] = kmeans.predict(x_test.loc[:, ['year','highwaympg']])\n",
        "\n",
        "X.plot(kind = 'scatter', x = 'highway',y ='year', hue='pred')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85e7fd7",
      "metadata": {
        "id": "e85e7fd7"
      },
      "source": [
        "# Best performing model\n",
        "### Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf915202",
      "metadata": {
        "id": "cf915202"
      },
      "outputs": [],
      "source": [
        "print('Model_std_value and Mean ',new_y_pred.std() , new_y_pred.mean())\n",
        "print('Model_model\\'s R2_score: ', r2_score(y_test['co2emissions'],new_y_pred))\n",
        "print('MSE', mean_squared_error(y_test['co2emissions'],new_y_pred))\n",
        "print('RMSE', np.sqrt(mean_squared_error(y_test['co2emissions'],new_y_pred)))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}